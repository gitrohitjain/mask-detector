{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath = 'deploy.prototxt.txt'\n",
    "weightsPath = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
    "\n",
    "faceNet = cv2.dnn.readNet(prototxtPath,weightsPath)\n",
    "maskNet = model = torch.load('oct.pt',map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = T.Compose([T.Resize((224,224)),\n",
    "                             T.ToTensor(),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mask(frame):\n",
    "    (h,w) = frame.shape[0:2]\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(image= frame,\n",
    "                             scalefactor= 1.0,\n",
    "                             size= (300,300),\n",
    "                             mean= (104.0,177.0,123.0))\n",
    "    \n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "    \n",
    "    image = frame.copy()\n",
    "\n",
    "    #loop over the detections\n",
    "    for i in range(detections.shape[2]):\n",
    "\n",
    "        confidence = detections[0,0,i,2]\n",
    "\n",
    "        if confidence>0.5:\n",
    "\n",
    "            #we need the X,Y coordinates as integers\n",
    "            box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "            (startX,startY,endX,endY) = box.astype('int')\n",
    "\n",
    "            #to ensure the bounding boxes fall within the dimensions of the frame\n",
    "            (startX,startY) = ( max(0,startX), max(0,startY))\n",
    "            (endX,endY) = (min(w-1,endX), min(h-1,endY))\n",
    "\n",
    "            #extract the face ROI, convert it from BGR to RGB channel, resize it to 224,224 and preprocess it\n",
    "            face = image[startY:endY, startX:endX]\n",
    "            face = cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            maskNet.eval()\n",
    "\n",
    "            face = Image.fromarray(face)\n",
    "            face = test_transforms(face).float()\n",
    "            face = torch.autograd.Variable(face, requires_grad=True)\n",
    "            face = face.unsqueeze(0)\n",
    "            output = maskNet(face)\n",
    "            conf, predicted = torch.max(output.data, 1)\n",
    "            mask = predicted.item()\n",
    "\n",
    "            #determine the class label and color we will use to draw the bounding box and text\n",
    "            label='Mask' if mask == 0 else 'No Mask'\n",
    "\n",
    "            color= (0,255,0) if label=='Mask' else (0,0,255)\n",
    "\n",
    "            #display the label and bounding boxes\n",
    "            cv2.putText(image,label,(startX,startY-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,color,2)\n",
    "            final = cv2.rectangle(image,(startX,startY),(endX,endY),color,2)\n",
    "            return final\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return frame\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs= VideoStream(src=0).start()\n",
    "\n",
    "while True:\n",
    "    #grab the frame from the threaded video stream and resize it\n",
    "    #to have a maximum width of 400 pixels\n",
    "    frame=vs.read()\n",
    "    frame=imutils.resize(frame,width=400)\n",
    "    \n",
    "    frame = predict_mask(frame)\n",
    "    \n",
    "    #show the output frame\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    key=cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
